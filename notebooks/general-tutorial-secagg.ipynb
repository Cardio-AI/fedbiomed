{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Secure Aggregation\n",
    "Secure aggregation is one of the security feature that is provided by Fed-BioMed. Please refer to secure aggregation user guide for more information regarding the methods and techniques that are used. This tutorial gives an example of secure aggregation usage in Fed-BioMed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the nodes\n",
    "\n",
    "During the tutorial, nodes and researcher will be launched locally using single clone of Fed-BioMed. However, it is also possible to execute notebook cells when the components are configured remotely by respecting following instruction.\n",
    "\n",
    "### Start the network\n",
    "Before running this notebook, start the network with `./scripts/fedbiomed_run network`\n",
    "\n",
    "### Configuring/Installing  Element for Secure Aggregation\n",
    "\n",
    "You can follow the detailed instructions for configuring Fed-BioMed instance for secure aggregation] or apply following shortened instructions for a basic setup.\n",
    "\n",
    "#### 1. Install and configure\n",
    "\n",
    "Fed-BioMed uses MP-SPDZ for MPC. Therefore, please make sure that MP-SPDZ are installed and configured for Fed-BioMed by running following command.\n",
    "\n",
    "\n",
    "```\n",
    "${FEDBIOMED_DIR}/scripts/fedbiomed_configure_secagg node\n",
    "```\n",
    "\n",
    "<div class=\"Note\">\n",
    "    <p>Since node and researcher will be run in the same machine, single configuration for MP-SDPZ will enouhg</>\n",
    "</div>\n",
    "\n",
    "#### 2. Create node and researcher instances\n",
    "\n",
    "The setup for secure aggregation requires knowledge of the participating Fed-BioMed components in advance. Therefore, each component that will participate in the training should be created before starting them. Afterwards, participating components can be registered in every other component.\n",
    "\n",
    "##### 2.1\n",
    "It is mandatory to have at least two nodes for the experiment that requires secure aggregation. Please execute following commands to create two nodes.\n",
    "\n",
    "Node 1:\n",
    "```\n",
    "${FEDBIOMED_DIR}/scripts/fedbiomed_run node config config-n1.ini configuration create\n",
    "```\n",
    "\n",
    "Node 2:\n",
    "```\n",
    "${FEDBIOMED_DIR}/scripts/fedbiomed_run node config config-n2.ini configuration create\n",
    "```\n",
    "\n",
    "##### 2.2 Create researcher\n",
    "\n",
    "Please run the command below to create researcher component.\n",
    "\n",
    "```\n",
    "${FEDBIOMED_DIR}/scripts/fedbiomed_run researcher configuration create\n",
    "```\n",
    "\n",
    "\n",
    "#### 3. Registering participating Fed-BioMed instances\n",
    "\n",
    "Normally, as it is mentioned in secure aggregation configuration each participating instance should register network credentials of others such as IP, port and SSL certificate. however, since this example will be run on single clone of Fed-BioMed, registration process can be done automaticity by running following command.\n",
    "\n",
    "```\n",
    "${FEDBIOMED_DIR}/scripts/fedbiomed_run certicate-dev-setup\n",
    "```\n",
    "\n",
    "#### 4. Add dataset and start nodes\n",
    "\n",
    "The next step will be adding/deploying MNIST dataset in the nodes and starting them. For these step you can follow the instructions for adding dataset into nodes to add MNIST dataset. After the datasets are deployed you can start the nodes and researcher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an experiment model and parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare a torch training plan MyTrainingPlan class to send for training on the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Here we define the model to be used. \n",
    "# You can use any class name (here 'Net')\n",
    "class MyTrainingPlan(TorchTrainingPlan):\n",
    "    \n",
    "    # Defines and return model \n",
    "    def init_model(self, model_args):\n",
    "        return self.Net(model_args = model_args)\n",
    "    \n",
    "    # Defines and return optimizer\n",
    "    def init_optimizer(self, optimizer_args):\n",
    "        return torch.optim.Adam(self.model().parameters(), lr = optimizer_args[\"lr\"])\n",
    "    \n",
    "    # Declares and return dependencies\n",
    "    def init_dependencies(self):\n",
    "        deps = [\"from torchvision import datasets, transforms\"]\n",
    "        return deps\n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, model_args):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.dropout1 = nn.Dropout(0.25)\n",
    "            self.dropout2 = nn.Dropout(0.5)\n",
    "            self.fc1 = nn.Linear(9216, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = self.dropout1(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            x = self.fc2(x)\n",
    "\n",
    "\n",
    "            output = F.log_softmax(x, dim=1)\n",
    "            return output\n",
    "\n",
    "    def training_data(self):\n",
    "        # Custom torch Dataloader for MNIST data\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        dataset1 = datasets.MNIST(self.dataset_path, train=True, download=False, transform=transform)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=dataset1, **train_kwargs)\n",
    "    \n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss   = torch.nn.functional.nll_loss(output, target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This group of arguments correspond respectively:\n",
    "* `model_args`: a dictionary with the arguments related to the model (e.g. number of layers, features, etc.). This will be passed to the model class on the node side.\n",
    "* `training_args`: a dictionary containing the arguments for the training routine (e.g. batch size, learning rate, epochs, etc.). This will be passed to the routine on the node side.\n",
    "\n",
    "**NOTE:** typos and/or lack of positional (required) arguments will raise error. ðŸ¤“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_args = {}\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 48, }, \n",
    "    'optimizer_args': {\n",
    "        \"lr\" : 1e-3\n",
    "    },\n",
    "    'epochs': 1, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare and run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:08:12,082 fedbiomed INFO - Starting researcher service...\n",
      "2023-11-10 15:08:12,083 fedbiomed INFO - Waiting 3s for nodes to connect...\n",
      "2023-11-10 15:08:13,763 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:08:14,209 fedbiomed DEBUG - Node: node_56066d82-ae6e-411b-a06b-8eec48f17acd polling for the tasks\n",
      "2023-11-10 15:08:15,106 fedbiomed DEBUG - Node: node_56066d82-ae6e-411b-a06b-8eec48f17acd polling for the tasks\n",
      "2023-11-10 15:08:15,127 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:08:15,599 fedbiomed INFO - Node selected for training -> node_01f09341-906f-4cc9-81c7-0bd9882c5c15\n",
      "2023-11-10 15:08:15,601 fedbiomed INFO - Node selected for training -> node_56066d82-ae6e-411b-a06b-8eec48f17acd\n",
      "2023-11-10 15:08:15,618 fedbiomed DEBUG - Model file has been saved: /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/experiments/Experiment_0134/my_model_8e55310a-30b2-4570-a889-27b4a48cfa09.py\n",
      "Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "2023-11-10 15:08:15,654 fedbiomed DEBUG - using native torch optimizer\n"
     ]
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "from fedbiomed.researcher.secagg import SecureAggregation\n",
    "tags =  ['#MNIST', '#dataset']\n",
    "rounds = 2\n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 model_args=model_args,\n",
    "                 training_plan_class=MyTrainingPlan,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage(),\n",
    "                 node_selection_strategy=None,\n",
    "                 secagg=True, # or custom SecureAggregation(active=<bool>, clipping_range=<int>, timeout=<int>)\n",
    "                 save_breakpoints=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access secure aggregation context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use the attribute `secagg` to verify secure aggregation is set as active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Is using secagg: \", exp.secagg.active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to check secure aggregation context using `secagg` attribute. Since secure aggregation context negotiation will occur during experiment run, context and id should be `None` at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Secagg Biprime \", exp.secagg.biprime)\n",
    "print(\"Secagg Servkey \", exp.secagg.servkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, using secure aggregation. Secure aggregation context will be created before the first training round, and it is going to be updated before each round when new nodes are added or removed to the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:08:23,258 fedbiomed DEBUG - Secagg context for default_biprime0 is already existing on researcher researcher_id='researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8'\n",
      "2023-11-10 15:08:23,262 fedbiomed INFO - Node node_56066d82-ae6e-411b-a06b-8eec48f17acd is in WAITING status. Server is waiting for receiving a request from this node to convert it as ACTIVE. Node will be updated as DISCONNECTED soon if no request received.\n",
      "2023-11-10 15:08:23,285 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:08:29,282 fedbiomed WARNING - Node node_56066d82-ae6e-411b-a06b-8eec48f17acd is disconnected. Request/task that are created for this node will be flushed\n",
      "2023-11-10 15:08:29,297 fedbiomed INFO - Node node_56066d82-ae6e-411b-a06b-8eec48f17acd is disconnected. Discard message.\n",
      "2023-11-10 15:08:29,308 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "Fed-BioMed researcher stopped due to exception:\n",
      "Request is not successful. Policy report => {'node_56066d82-ae6e-411b-a06b-8eec48f17acd': 'StopOnDisconnect'}. Errors => {}\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:09:00,464 fedbiomed DEBUG - MPC protocol output: \n",
      "\t\t\t\t\t\t \u001b[1;32mCloning MP-SPDZ into the MPC working directory ...\u001b[0m\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\tDoing /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/MP-SPDZ/Player-Data\n",
      "\t\t\t\t\t\t\u001b[1;32mCompiling 'server_key'...\u001b[0m\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\u001b[1;32mCompilation is successful!\u001b[0m\n",
      "\t\t\t\t\t\t##########################################################################\n",
      "\t\t\t\t\t\tDefault bit length: 2048\n",
      "\t\t\t\t\t\tDefault security parameter: 40\n",
      "\t\t\t\t\t\tCompiling: server_key from compile_func\n",
      "\t\t\t\t\t\tWriting to /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/MP-SPDZ/Programs/Schedules/server_key.sch\n",
      "\t\t\t\t\t\tWriting to /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/MP-SPDZ/Programs/Bytecode/server_key-0.bc\n",
      "\t\t\t\t\t\tProgram requires at most:\n",
      "\t\t\t\t\t\t         inf integer inputs from player 0\n",
      "\t\t\t\t\t\t           1 virtual machine rounds\n",
      "\t\t\t\t\t\t##########################################################################\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\u001b[1;33mExecution info:\u001b[0m\n",
      "\t\t\t\t\t\t\u001b[1;33m---------------------------------------\u001b[0m\n",
      "\t\t\t\t\t\t\u001b[1mParty no          :\u001b[0m 0\n",
      "\t\t\t\t\t\t\u001b[1mNumber of parties :\u001b[0m 3\n",
      "\t\t\t\t\t\t\u001b[1mAssigned IPs      :\u001b[0m /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/ip_addresses\n",
      "\t\t\t\t\t\t\u001b[1mOutput file       :\u001b[0m /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/Output-P0-0\n",
      "\t\t\t\t\t\t\u001b[1;32mExecuting protocol 'shamir-party'...\u001b[0m\n",
      "\t\t\t\t\t\t\u001b[1mPress CTRL+C to stop\u001b[0m\n",
      "\t\t\t\t\t\tUsing security parameter 40\n",
      "\t\t\t\t\t\t\n",
      "2023-11-10 15:09:00,466 fedbiomed DEBUG - FB620: MPC protocol error: MPC computation for RESEARCHER is not successful.. Details: \u001b[1;32mCloning MP-SPDZ into the MPC working directory ...\u001b[0m\n",
      "\n",
      "Doing /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/MP-SPDZ/Player-Data\n",
      "\u001b[1;32mCompiling 'server_key'...\u001b[0m\n",
      "\n",
      "\u001b[1;32mCompilation is successful!\u001b[0m\n",
      "##########################################################################\n",
      "Default bit length: 2048\n",
      "Default security parameter: 40\n",
      "Compiling: server_key from compile_func\n",
      "Writing to /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/MP-SPDZ/Programs/Schedules/server_key.sch\n",
      "Writing to /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/MP-SPDZ/Programs/Bytecode/server_key-0.bc\n",
      "Program requires at most:\n",
      "         inf integer inputs from player 0\n",
      "           1 virtual machine rounds\n",
      "##########################################################################\n",
      "\n",
      "\n",
      "\u001b[1;33mExecution info:\u001b[0m\n",
      "\u001b[1;33m---------------------------------------\u001b[0m\n",
      "\u001b[1mParty no          :\u001b[0m 0\n",
      "\u001b[1mNumber of parties :\u001b[0m 3\n",
      "\u001b[1mAssigned IPs      :\u001b[0m /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/ip_addresses\n",
      "\u001b[1mOutput file       :\u001b[0m /home/scansiz/projects/fedbiomed-dev/fedbiomed/var/tmp/MPC/researcher_019e9631-63d3-44b4-ab96-fe1808c47bd8/14c86e64-5874-4749-a93c-ae4d6381c04a/Output-P0-0\n",
      "\u001b[1;32mExecuting protocol 'shamir-party'...\u001b[0m\n",
      "\u001b[1mPress CTRL+C to stop\u001b[0m\n",
      "Using security parameter 40\n",
      "\n"
     ]
    },
    {
     "ename": "FedbiomedSilentTerminationError",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:09:29,310 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:09:40,399 fedbiomed WARNING - A reply received from an federated request has been stopped: f17da597-9e02-4a95-bbbb-0962673a6294. This reply has been received form the node that didn't not cause stopping\n",
      "2023-11-10 15:10:29,313 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:11:29,316 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:12:29,319 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:13:29,322 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:14:29,325 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:15:29,328 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:16:29,330 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:17:29,333 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:18:29,335 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:19:29,340 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:20:29,341 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:21:29,344 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n",
      "2023-11-10 15:22:29,346 fedbiomed DEBUG - Node: node_01f09341-906f-4cc9-81c7-0bd9882c5c15 polling for the tasks\n"
     ]
    }
   ],
   "source": [
    "exp.run(rounds=2, increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display context after running one round of training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Secagg Biprime context: \", exp.secagg.biprime.context)\n",
    "print(\"Secagg Servkey context: \", exp.secagg.servkey.context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changes in experiment triggers re-creation of secure aggregation context\n",
    "\n",
    "The changes that re-create jobs like adding new node to the experiment will trigger automatic secure aggregation re-setup for the next round.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sends new dataset search request\n",
    "from fedbiomed.researcher.strategies import DefaultStrategy\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "exp.set_training_data(None, True)\n",
    "exp.set_strategy(DefaultStrategy)\n",
    "exp.set_aggregator(FedAverage)\n",
    "exp.set_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing arguments of secure aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `secagg` argument `True` in `Experiment` creates a default `SecureAggregation` instance. Additionally, It is also possible to create `SecureAggregation` instance and pass it as an argument. Here are the arguments that can be set for the `SecureAggregation`\n",
    "\n",
    "- `active`: `True` if the round will use secure aggregation. Default is `True`\n",
    "- `clipping_range`: Clipping range that is going be use for quantization of model parameters. Default clipping range is `3`. However, some models can have model weigths greater than `3`. If clipping range is exceeded during the encryption on the nodes, `Experiment` will log a warning message. In such cases, you can provide a higher clipping range through the argument `clipping_range`.\n",
    "- `timeout`: Timeout is the maximum amount of time, in seconds, that the experiment will wait for responses from all parties during secure aggregation setup. Since secure aggregation context depends on network communication and multi-party computation, this argument allows setting higher timeout for larger context setups, or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.secagg import SecureAggregation\n",
    "secagg = SecureAggregation(\n",
    "    active=True, \n",
    "    clipping_range=100,\n",
    "    timeout=15\n",
    "    \n",
    ")\n",
    "exp.set_secagg(secagg=secagg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run_once(increase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experiment from a breakpoint\n",
    "\n",
    "Once a breakpoint is loadded if the context is already exsiting there won't be context setup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loaded_exp = Experiment.load_breakpoint()\n",
    "loaded_exp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_exp.run_once(increase=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
