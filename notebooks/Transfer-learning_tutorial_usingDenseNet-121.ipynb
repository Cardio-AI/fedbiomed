{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73501475-4e1f-454c-bc16-0320ecd51d57",
   "metadata": {},
   "source": [
    "# Transfer-learning tutorial using DenseNet-121 pre-trained model:\n",
    "# example on MedNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d343c58-9d11-400f-9e2e-9b0d1e840105",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial shows how to do 2d image classification example on MedNIST dataset using pretrained PyTorch model Densnet121 [] https://pytorch.org/vision/main/generated/torchvision.models.densenet121.html.\n",
    "\n",
    "## Goal of this tutoriel\n",
    "\n",
    "The goal of this tutorial is to provide an example of transfer learning methods with Fed-BioMed for medical images classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4648375-0340-428a-88cf-97c5a52f5560",
   "metadata": {},
   "source": [
    "## About the model\n",
    "\n",
    "The model used is Densenet-121 model(“Densely Connected Convolutional Networks”) pretrained on ImageNet dataset. The Pytorch pretrained Densenet121 is used https://pytorch.org/vision/main/generated/torchvision.models.densenet121.html to perform image classification on the MedNIST dataset. \n",
    "The goal of this Densenet121 model is to predict the class of the image modality given the medical image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463ce8b-8c65-4d51-85ad-47ce8fbc5528",
   "metadata": {},
   "source": [
    "### About MedNIST\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "MedNIST dataset is downloaded from the resources provided by the project MONAI: https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\n",
    "\n",
    "The dataset MedNIST has 58954 images of size (3, 64, 64) distributed into 6 classes (10000 images per class except for BreastMRI class which has 8954 images). Classes are AbdomenCT, BreastMRI, CXR, ChestCT, Hand, HeadCT. It has the structure:\n",
    "\n",
    "└── MedNIST/\n",
    "\n",
    "    ├── AbdomenCT/\n",
    "\n",
    "    └── BreastMRI/\n",
    "\n",
    "    └── CXR/\n",
    "\n",
    "    └── ChestCT/\n",
    "\n",
    "    └── Hand/\n",
    "\n",
    "    └── HeadCT/   \n",
    "   \n",
    "\n",
    "### Transfer-learning\n",
    "Transfer learning is a machine learning technique where a model trained on one task is repurposed or adapted for a second related task. Transfer learning uses a pre-trained neural network on a large dataset, as Imagenet is used to train DenseNet model to perform classification of a wide diversity of images.\n",
    "\n",
    "The objective is that the knowledge gained from learning one task can be useful for learning another task (as we do here, classification of medical images in 6 categories). This is particularly beneficial when the amount of labeled data for the target task is limited, as the pre-trained model has already learned useful features and representations from a large dataset.\n",
    "\n",
    "Transfer learning is typically applied in one of two ways:\n",
    "\n",
    "- Feature Extraction: In this approach, the pre-trained model is used as a fixed feature extractor. The earlier layers of the neural network, which capture general features and patterns, are frozen, and only the later layers are replaced or retrained for the new task. \n",
    "\n",
    "- Fine-tuning: In this approach, the pre-trained model is further trained or partially trained on the new task. This allows the model to adapt its learned representations to the specifics of the new task while retaining some of the knowledge gained from the original task.\n",
    "\n",
    "\n",
    "In this example, we load on the node a sampled dataset ( 500 or 1000 images) of MedNIST to illustrate the effectiveness of the transfer learning. The sampled dataset is made with a random selection of images and return a sampled dataset with balanced classes, to avoid classification's bias.\n",
    "We will test these two approches through two independant TrainingPlan experiments. \n",
    "To illustrate the effectiveness of these two method, we load 500 images for the first experiment and 1000 images for the second. Because the fine tunng method involves more layers's training, this method is better efficient for large datatsets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef72375-5f3e-4e29-b619-e172055a01b5",
   "metadata": {},
   "source": [
    "## Setup the node\n",
    "\n",
    "- From the folder fedbiomed, execute the command ./scripts/fedbiomed_run node add\n",
    "\n",
    "- Select option 3 (mednist) to add MedNIST to the node\n",
    "- Confirm mednist tags ['#MEDNIST', '#dataset'] by hitting \"y\" and ENTER\n",
    "- Select the folder where MedNIST is downloaded (It will be downloaded if it is not found in the selected path)\n",
    "Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "- Enter the amount's sample you want to run in your experiment.\n",
    "\n",
    "- Check that your data has been added by executing ./scripts/fedbiomed_run node list\n",
    "- Start the node using ./scripts/fedbiomed_run node start. Wait until you get Starting task manager.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9e20f-6b16-4150-a3a4-1f4a2c468aa5",
   "metadata": {},
   "source": [
    "## Start Fed-BioMed Researcher\n",
    "\n",
    "We are now ready to start the researcher environment with the command source ./scripts/fedbiomed_run researcher start\n",
    ", and open the Jupyter notebook.\n",
    "\n",
    "To make sure that MedNIST dataset is loaded in the node we can send a request to the network to list the available dataset in the node. The list command should output an entry for mednist data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf52151-a981-4189-8be4-ea5ca03fd120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req  = Requests()\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20148877-d424-4793-9d8b-693d2e47ba44",
   "metadata": {},
   "source": [
    "## Import of librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae87e6a-94ac-4ecf-9586-8f9a353fb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import densenet121\n",
    "from torchvision import datasets, transforms, models\n",
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a775bd-4d9e-4f59-9c18-4257ff8ea314",
   "metadata": {},
   "source": [
    "## Run an expriment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf14e-d695-4831-8bdf-0e09f7c2f53e",
   "metadata": {},
   "source": [
    "### 1. Load dataset or sampled dataset\n",
    "- From the root directory of Fed-BioMed, run :  source ./scripts/fedbiomed_environment node in order to load the Node environment\n",
    "- If you have already ran Mednist nodes before, clean remaining MedNIST nodes : run ./scripts/fedbiomed_run node delete or source ./scripts/fedbiomed_environment clean\n",
    "- In this new environment, run the script python: python ./notebooks/transfer-learning/download_sample_of_mednist.py -n <number-of-nodes>, with <number-of-nodes> the number of Nodes you want to create( for more details about this script, please run notebooks/transfer-learning/download_sample_of_mednist.py --help)\n",
    "- The script will ask for each Nodes created the number of samples you want for your dataset. Scripts will output configuration files for each of Nodes, with configured database.  \n",
    "- Finally launch your Nodes (one by terminal) by running: ./scripts/fedbiomed_run node config  start config_mednist_<i>_sampled.ini start, where <i> corresponds to the number of Node created.  Wait until you get Starting task manager.\n",
    "\n",
    "### 2. Launch the researcher \n",
    "- From the root directory of Fed-BioMed, run : ./scripts/fedbiomed_run researcher start\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b66b5-af52-45e4-944b-572fb12504dc",
   "metadata": {},
   "source": [
    "## Classification using Transfer-learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567f368-0dc6-4eaa-95a6-1f7a6e78c6e7",
   "metadata": {},
   "source": [
    "### Adapt the last layer to your classification's goal\n",
    "Here we use the DenseNet model that allows classification through 1000 classes. \n",
    "We could adapt this classification's task to the MedNIST dataset by replacing the last layer with our classifier. \n",
    "The model.classifier classify images through 6 classes, by adapting the num_classes value. \n",
    "\n",
    "### Data augmentation\n",
    "You could perform data augmentation through the preprocess part if you need. Here I show random flip, rotation and crops. \n",
    "You could do the preprocessing of images by doing only transforms.resize, transforms.to_tensor and transforms.normalize, as mentionned in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43761a76-1efc-46cc-80b6-161b3c99731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainingPlan1(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "       \n",
    "        # Load the pre-trained DenseNet model\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # Remove the classification layer of DenseNet\n",
    "        for param in model.features[:-1].parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # add the classifier \n",
    "        num_classes = model_args['num_classes'] \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier= nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "      \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\",\n",
    "            \"from torchvision.models import densenet121\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    \n",
    "    # training data\n",
    "    \n",
    "    def training_data(self):\n",
    "        \n",
    "        # Custom torch Dataloader for MedNIST data\n",
    "        print(\"dataset path\",self.dataset_path)\n",
    "\n",
    "        # Transform images and  do data augmentation \n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomVerticalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(30),\n",
    "                #transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a011a997-5fc6-4d01-af73-54c6017da976",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-3}, \n",
    "    'epochs': 2, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'num_classes': 6 # adapt this number to the number of classes in your dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f594a9-8d00-464b-80f1-ff42dac59b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:40,858 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:40,861 fedbiomed INFO - No available dataset has found in nodes with tags: ['#MEDNIST', '#dataset']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:40,866 fedbiomed DEBUG - Model file has been saved: /home/ebirgy/development/fedbiomed_github/fedbiomed/var/experiments/Experiment_0081/model_4915028e-f101-4b40-bcf4-1ab87310931d.py"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:41,128 fedbiomed DEBUG - using native torch optimizer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:41,129 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:41,129 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:41,130 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags =  ['#MEDNIST', '#dataset']\n",
    "\n",
    "rounds = 2 # adjsut the number of rounds \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan1,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "# testing section \n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1) \n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4087e8b5-cad2-4436-9d85-6686717ba8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:49,929 fedbiomed INFO - Sampled nodes in round 0 []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:31:49,938 fedbiomed INFO - Nodes that successfully reply in round 0 []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "Fed-BioMed researcher stopped due to exception:\n",
      "FB401: aggregation crashes or returns an error. Aggregation aborted due to sum of the weights is equal to 0 {}. Sample sizes received from nodes might be corrupted.\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "FedbiomedSilentTerminationError",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:32:23,713 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:33:23,705 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:33:34,487 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:34:34,486 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:34:44,891 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:35:44,891 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:35:49,194 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:36:49,189 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:36:56,921 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:37:56,917 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:38:12,417 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:39:12,418 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:39:25,842 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:40:25,836 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:40:36,647 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-05 10:41:13,053 fedbiomed WARNING - Node config_mednist_1_sampled is disconnected. Request/task that are created for this node will be flushed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecf6a7-eb26-4b9c-bc24-492c8cb030b8",
   "metadata": {},
   "source": [
    "###### For example,  At the end of training experiment, I obtained\n",
    "\n",
    "                      INFO - VALIDATION ON LOCAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: NODE_41cd99c8-3571-4ab3-958e-6357ce31e91b \n",
    "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 0.960000\n",
    "\t\t\t\t\t -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244b54a8-43a0-4009-8e3e-07e62fec2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "exp.training_plan().export_model('./training_plan1_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ace09-7f4d-40fd-8646-c3f4cb67042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "tensorboard_dir = environ['TENSORBOARD_RESULTS_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31041e7e-728d-4b18-a5d7-58f405bd1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bdb39-287e-4cc4-973d-1dfb30838aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072c19d-f932-4926-8290-349601908054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6699bc5e-c3a0-46ca-8162-9a52a8c2d020",
   "metadata": {},
   "source": [
    "## Upload more data and train the top layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71095e37-bcc7-44f0-b049-15401e25d1e5",
   "metadata": {},
   "source": [
    "You can load more data on a new node for the second experiment and train top layers of the denseNet model.\n",
    "To cange the amount of data, you have to stop the previous node in the console by tapping CTL+C.\n",
    "\n",
    "In this example, I run a second experiment with 1000 images.\n",
    "Run an other node with 1000 images (as previously described above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59fb9cb-0ff6-4d5b-935f-a6f7d5eae3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req  = Requests()\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07027428-86f9-4f0f-87da-b8b97da6838e",
   "metadata": {},
   "source": [
    "## Partial fine-tuning: Use pretrained DenseNet and train top layers with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62ced6-f7e6-406f-8dfe-77e620aa3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainingPlan2(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "\n",
    "        # Load the pre-trained DenseNet model\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # For example, let's freeze layers of the last dense block\n",
    "        for param in model.features[:-3].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # add the classifier \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        num_classes = model_args['num_classes'] \n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes)       \n",
    "            )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    def training_data(self):\n",
    "        \n",
    "        # Custom torch Dataloader for MedNIST data and transform images and perform data augmentation \n",
    "        print(\"dataset path\",self.dataset_path)\n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomVerticalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(30),\n",
    "                #transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f3099-b6e6-4395-b9ea-ad2b728d0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-4}, # You could decrease the learning rate\n",
    "    'epochs': 1, # you can increase the epoch's number =10\n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "model_args={\n",
    "    'num_classes': 6\n",
    "}\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "rounds = 1  # you can increase the rounds's number \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan2,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1)\n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3e1a9-b0c8-4bbc-b397-0d0b6b14ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaec824-4a01-4c29-b9d9-f4543c8d56ff",
   "metadata": {},
   "source": [
    "For example,  At the end of training experiment, I obtained\n",
    "\n",
    "                    fedbiomed INFO - VALIDATION ON LOCAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: NODE_7842724a-cafa-49cc-862d-149288bbbb22 \n",
    "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 0.990000 \n",
    "\t\t\t\t\t ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394f0b1-5795-479e-a544-dc07913ac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1]\n",
    "for r in round_data.values():\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = r['node_id'],\n",
    "        rtraining = r['timing']['rtime_training'],\n",
    "        ptraining = r['timing']['ptime_training'],\n",
    "        rtotal = r['timing']['rtime_total']))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d301fa3-50e7-4aee-96d6-b85bed457fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b73071-f09b-4a87-a0a6-d525ce39c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f51d1b-960f-4b4b-b301-7c7ea7c68c9a",
   "metadata": {},
   "source": [
    "## Save and export your model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a311890f-bab1-4970-a501-98f285d70fbd",
   "metadata": {},
   "source": [
    "You can save the TrainingPlan experiment and the fine-tune model by executing the command below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e2eb8-2441-4966-a619-5bf587db2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().export_model('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d0692-df7f-490c-a250-39758470349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model ( all layers model of te training experiment)\n",
    "remote_model = exp.training_plan().model()\n",
    "torch.save(remote_model, './training_plan2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdc0bb-be22-46e3-944a-9cdbd8162a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision import models\n",
    "\n",
    "#torch.save(models.densenet121(pretrained=True).state_dict(), './model_training_plan_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428af67-79a8-4cee-8b6b-ad5b010bb411",
   "metadata": {},
   "source": [
    "## Import your model and parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e589df-9589-4a78-9878-790f83e0cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model = torch.load('./training_plan2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457eeeb-0618-4f0e-adaa-e0ce03ab21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your parameters (tensors's values of your tuned-model)\n",
    "tuned_model= torch.load('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b4373-1716-417a-8b28-fd1dfc76ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new TrainingPlan experiment you could import your tuned-model \n",
    "exp.training_plan().import_model('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef8f1a-7b6b-4e3b-8351-a78d97964084",
   "metadata": {},
   "source": [
    "### This part needs confirmation, tests,( and agreements to load parameters ? ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6510f7d-d612-476a-98aa-5aef2651f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remote_model = remote_experiment.training_plan().model()\n",
    "tuned_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e0cc6-770e-4a34-8037-9eae06bd45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])\n",
    "#tuned_model.load_state_dict(remote_experiment.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7346c-d6fb-45d3-804e-e56b0e9f3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82550831-bf50-480e-a0a9-f16511c48e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
