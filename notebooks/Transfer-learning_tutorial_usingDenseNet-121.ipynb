{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73501475-4e1f-454c-bc16-0320ecd51d57",
   "metadata": {},
   "source": [
    "# Transfer-learning tutorial using DenseNet-121 pre-trained model: example on MedNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d343c58-9d11-400f-9e2e-9b0d1e840105",
   "metadata": {},
   "source": [
    "\n",
    "## Goal of this tutoriel\n",
    "\n",
    "This tutorial shows how to do 2d images classification example on MedNIST dataset using pretrained PyTorch model.\n",
    "\n",
    "The goal of this tutorial is to provide an example of transfer learning methods with Fed-BioMed for medical images classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4648375-0340-428a-88cf-97c5a52f5560",
   "metadata": {},
   "source": [
    "## About the model\n",
    "\n",
    "The model used is Densenet-121 model(“Densely Connected Convolutional Networks”) pretrained on ImageNet dataset. The Pytorch pretrained model [Densenet121](https://pytorch.org/vision/main/models/generated/torchvision.models.html). to perform image classification on the MedNIST dataset. \n",
    "The goal of this Densenet121 model is to predict the class of `MedNIST` medical images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463ce8b-8c65-4d51-85ad-47ce8fbc5528",
   "metadata": {},
   "source": [
    "### About MedNIST\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "MedNIST dataset is downloaded from the resources provided by the project MONAI: https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\n",
    "\n",
    "The dataset MedNIST has 58954 images of size (3, 64, 64) distributed into 6 classes (10000 images per class except for BreastMRI class which has 8954 images). Classes are AbdomenCT, BreastMRI, CXR, ChestCT, Hand, HeadCT. It has the structure:\n",
    "\n",
    "└── MedNIST/\n",
    "\n",
    "    ├── AbdomenCT/\n",
    "\n",
    "    └── BreastMRI/\n",
    "\n",
    "    └── CXR/\n",
    "\n",
    "    └── ChestCT/\n",
    "\n",
    "    └── Hand/\n",
    "\n",
    "    └── HeadCT/   \n",
    "   \n",
    "\n",
    "### Transfer-learning\n",
    "Transfer learning is a machine learning technique where a model trained on one task is repurposed or adapted for a second related task. Transfer learning uses a pre-trained neural network on a large dataset, as Imagenet is used to train DenseNet model to perform classification of a wide diversity of images.\n",
    "\n",
    "The objective is that the knowledge gained from learning one task can be useful for learning another task (as we do here, classification of medical images in 6 categories). This is particularly beneficial when the amount of labeled data for the target task is limited, as the pre-trained model has already learned useful features and representations from a large dataset.\n",
    "\n",
    "Transfer learning is typically applied in one of two ways:\n",
    "\n",
    "- (I) Feature Extraction: In this approach, the pre-trained model is used as a fixed feature extractor. The earlier layers of the neural network, which capture general features and patterns, are frozen, and only the later layers are replaced or retrained for the new task. \n",
    "\n",
    "- (II) Fine-tuning: In this approach, the pre-trained model is further trained or partially trained on the new task. This allows the model to adapt its learned representations to the specifics of the new task while retaining some of the knowledge gained from the original task.\n",
    "\n",
    "\n",
    "In this example, we load on the node a sampled dataset ( 500 or 1000 images) of MedNIST to illustrate the effectiveness of the transfer learning. The sampled datasets are made with a random selection with balanced classes, to avoid classification's bias.\n",
    "We will test these two approches through two independant TrainingPlan experiments. \n",
    "To illustrate the effectiveness of these two method, we load 500 images for the first experiment and 1000 images for the second. The more data you have, the more layers's you can unfreeze for a transfer learning task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf14e-d695-4831-8bdf-0e09f7c2f53e",
   "metadata": {},
   "source": [
    "### 1. Load dataset or sampled dataset\n",
    "- From the root directory of Fed-BioMed, run :  `source ./scripts/fedbiomed_environment node` in order to load the Node environment\n",
    "- If you have already ran Mednist nodes before, clean remaining MedNIST nodes : run `./scripts/fedbiomed_run node delete` or `source ./scripts/fedbiomed_environment clean`\n",
    "- In this new environment, run the script python: `python ./notebooks/transfer-learning/download_sample_of_mednist.py -n <number-of-nodes>`, with `<number-of-nodes>` the number of Nodes you want to create( for more details about this script, please run `notebooks/transfer-learning/download_sample_of_mednist.py --help`)\n",
    "- The script will ask for each Nodes created the number of samples you want for your dataset. Scripts will output configuration files for each of Nodes, with configured database, using the following naming convention: `config_mednist_<i>_sampled.ini` where `<i>` is ranged from 1 to `<number-of-nodes>` entered.  \n",
    "- Finally launch your Nodes (one by terminal) by running: `./scripts/fedbiomed_run node config  start config_mednist_<i>_sampled.ini start`, where `<i>` corresponds to the number of Node created.  Wait until you get Starting task manager.\n",
    "\n",
    "For example, if one wants to create 2 nodes, (`<i>` is equal to 2), one has to run : `python ./notebooks/transfer-learning/download_sample_of_mednist.py -n 2`. One will then launch in seperated terminal `./scripts/fedbiomed_run node config  start config_mednist_1_sampled.ini start` and `./scripts/fedbiomed_run node config  start config_mednist_2_sampled.ini start`. Script will ask how many sample should contain the dataset (enter 500 and then 1000).\n",
    "\n",
    "### 2. Launch the researcher \n",
    "- From the root directory of Fed-BioMed, run : `./scripts/fedbiomed_run researcher start`\n",
    "- It opens the Jupyter notebook.\n",
    "\n",
    "To make sure that MedNIST dataset is loaded in the node we can send a request to the network to list the available dataset in the node. The list command should output an entry for mednist data.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf52151-a981-4189-8be4-ea5ca03fd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req  = Requests()\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20148877-d424-4793-9d8b-693d2e47ba44",
   "metadata": {},
   "source": [
    "## Import of librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae87e6a-94ac-4ecf-9586-8f9a353fb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "\n",
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a775bd-4d9e-4f59-9c18-4257ff8ea314",
   "metadata": {},
   "source": [
    "## Run an expriment for image's classification using Transfer-learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567f368-0dc6-4eaa-95a6-1f7a6e78c6e7",
   "metadata": {},
   "source": [
    "### I- Adapt the last layer to your classification's goal\n",
    "Here we use the DenseNet model that allows classification through 10000 samples. \n",
    "We could adapt this classification's task to the MedNIST dataset by replacing the last layer with our classifier. \n",
    "The `model.classifier` layer of the `DenseNet-121` model classifies images through 6 classes, in the Training Plan, by adapting the num_classes value (can be done in through `model_args` argument). \n",
    "\n",
    "### Data augmentation\n",
    "You could perform data augmentation through the preprocess part if you need. Here I show random flip, rotation and crops. \n",
    "You could do the preprocessing of images by doing only transforms.resize, transforms.to_tensor and transforms.normalize, as mentionned in the code below (commented lines). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f5b80",
   "metadata": {},
   "source": [
    "### 1.1. Define Training plan experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43761a76-1efc-46cc-80b6-161b3c99731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainingPlan1(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "       \n",
    "        # Load the pre-trained DenseNet model\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # Remove the classification layer of DenseNet\n",
    "        for param in model.features[:-1].parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # add the classifier \n",
    "        num_classes = model_args['num_classes'] \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier= nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "      \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\",\n",
    "            \"from torchvision.models import densenet121\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    \n",
    "    # training data\n",
    "    \n",
    "    def training_data(self):\n",
    "        \n",
    "        # Custom torch Dataloader for MedNIST data\n",
    "        print(\"dataset path\",self.dataset_path)\n",
    "\n",
    "        # Transform images and  do data augmentation \n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomVerticalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(30),\n",
    "                #transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011a997-5fc6-4d01-af73-54c6017da976",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-3}, \n",
    "    'epochs': 2, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'num_classes': 6 # adapt this number to the number of classes in your dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f594a9-8d00-464b-80f1-ff42dac59b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags =  ['#MEDNIST', '#dataset']\n",
    "\n",
    "rounds = 2 # adjsut the number of rounds \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan1,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "# testing section \n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1) \n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12fd54",
   "metadata": {},
   "source": [
    "### 1.2. Define the dataset for your experiment \n",
    "\n",
    "I propose to run this first experiment with only one Node (ie with  MedNIST_sampled_1 dataset, a sub-sampled dataset of 500 MedNIST images), because this first method is a transfer learning without training.\n",
    "\n",
    "Here I show how to select one dataset among the connected datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp.set_nodes(['config_mednist_1_sampled'])\n",
    "exp.set_tags(['#MEDNIST', '#dataset'])\n",
    "td = exp.training_data().data()\n",
    "td.pop('config_mednist_2_sampled')\n",
    "exp.set_training_data(td)\n",
    "\n",
    "print(exp.training_data().data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eee3f6",
   "metadata": {},
   "source": [
    "### 1.3. Run your experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087e8b5-cad2-4436-9d85-6686717ba8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecf6a7-eb26-4b9c-bc24-492c8cb030b8",
   "metadata": {},
   "source": [
    "###### For example,  At the end of training experiment, I obtained\n",
    "\n",
    "                      INFO - VALIDATION ON LOCAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: NODE_41cd99c8-3571-4ab3-958e-6357ce31e91b \n",
    "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 0.980000\n",
    "\t\t\t\t\t -\n",
    "\n",
    "As you can see, Accuracy has been increased in comparison to the first `Expermient`   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600b2ce",
   "metadata": {},
   "source": [
    "### 1.4. Save your model \n",
    "You could save your model to later use it in a new TrainingPlan \n",
    "This save allows to import the model including your layers's modification and weights values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b54a8-43a0-4009-8e3e-07e62fec2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "exp.training_plan().export_model('./training_plan1_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263f76b",
   "metadata": {},
   "source": [
    "### 1.5. Results in tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ace09-7f4d-40fd-8646-c3f4cb67042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "tensorboard_dir = environ['TENSORBOARD_RESULTS_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31041e7e-728d-4b18-a5d7-58f405bd1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bdb39-287e-4cc4-973d-1dfb30838aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07027428-86f9-4f0f-87da-b8b97da6838e",
   "metadata": {},
   "source": [
    "## II - Partial fine-tuning: Use pretrained DenseNet and train specific layers with your data\n",
    "You can set the second dataset with more images to run the second experiment that uses training steps. \n",
    "\n",
    "In this example, I run a second experiment with 1000 images.\n",
    "The dataset is defined below, after TrainingPlan as previously shown.\n",
    "\n",
    "You could also import the model you saved to perform your second TrainingPlan experiment (let's see below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req  = Requests()\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33207b0-6d38-4cb6-a1ed-7ea18e55b1ea",
   "metadata": {},
   "source": [
    "Here I freeze 3 layers since we have a bigger dataset than in the first part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62ced6-f7e6-406f-8dfe-77e620aa3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "class MyTrainingPlan2(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "\n",
    "        # Load the pre-trained DenseNet model\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # For example, let's freeze layers of the last dense block\n",
    "        for param in model.features[:-3].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # add the classifier \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        num_classes = model_args['num_classes'] \n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes)       \n",
    "            )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    def training_data(self):\n",
    "        \n",
    "        # Custom torch Dataloader for MedNIST data and transform images and perform data augmentation \n",
    "        print(\"dataset path\",self.dataset_path)\n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomVerticalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(30),\n",
    "                #transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f3099-b6e6-4395-b9ea-ad2b728d0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-4}, # You could decrease the learning rate\n",
    "    'epochs': 1, # you can increase the epoch's number =10\n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "model_args={\n",
    "    'num_classes': 6\n",
    "}\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "rounds = 1  # you can increase the rounds's number \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan2,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1)\n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb58d926",
   "metadata": {},
   "source": [
    "### 2.1- (Optional) Import a \"custom model\" or continue with the original DenseNet model of the TrainingPlan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25160054",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().import_model('./training_plan1_densenet_MedNIST') # if you want to import the model and weights of first traning plan "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4050a598",
   "metadata": {},
   "source": [
    "### 2.2. Define the dataset foryour experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12059faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.set_nodes(['config_mednist_2_sampled'])\n",
    "exp.set_tags(['#MEDNIST', '#dataset'])\n",
    "td = exp.training_data().data()\n",
    "td.pop('config_mednist_1_sampled')\n",
    "exp.set_training_data(td)\n",
    "\n",
    "print(exp.training_data().data())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829e80f",
   "metadata": {},
   "source": [
    "### 2.3. Run your experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3e1a9-b0c8-4bbc-b397-0d0b6b14ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaec824-4a01-4c29-b9d9-f4543c8d56ff",
   "metadata": {},
   "source": [
    "For example,  At the end of training experiment, I obtained\n",
    "\n",
    "                    fedbiomed INFO - VALIDATION ON LOCAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: NODE_7842724a-cafa-49cc-862d-149288bbbb22 \n",
    "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 1.00000\n",
    "\t\t\t\t\t ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394f0b1-5795-479e-a544-dc07913ac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1]\n",
    "for r in round_data.values():\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = r['node_id'],\n",
    "        rtraining = r['timing']['rtime_training'],\n",
    "        ptraining = r['timing']['ptime_training'],\n",
    "        rtotal = r['timing']['rtime_total']))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f51d1b-960f-4b4b-b301-7c7ea7c68c9a",
   "metadata": {},
   "source": [
    "### 2.4. Save and export your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "exp.training_plan().export_model('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2acea",
   "metadata": {},
   "source": [
    "### 2.5. Display losses on Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d301fa3-50e7-4aee-96d6-b85bed457fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b73071-f09b-4a87-a0a6-d525ce39c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4668ca",
   "metadata": {},
   "source": [
    "### 2.6. Save and Import your model and parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efaf44",
   "metadata": {},
   "source": [
    "You could import your first model from TrainingPlan1 instead of loading the original DenseNet.\n",
    "You could also retrieve the model's weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model ( all layers model of te training experiment)\n",
    "remote_model = exp.training_plan().model()\n",
    "torch.save(remote_model, './training_plan2_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e906de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your model \n",
    "model= torch.load('./training_plan2_model')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b05c4",
   "metadata": {},
   "source": [
    "### 2.7. Save features weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights=exp.training_plan().export_model('./training_plan2_model')\n",
    "model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c18ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and display your model's weights \n",
    "model_weights_= torch.load('./training_plan2_model')\n",
    "model_weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6510f7d-d612-476a-98aa-5aef2651f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work in last version ?\n",
    "# extract model weights \n",
    "remote_model = exp.training_plan().model()\n",
    "remote_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82550831-bf50-480e-a0a9-f16511c48e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
