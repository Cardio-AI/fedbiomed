{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73501475-4e1f-454c-bc16-0320ecd51d57",
   "metadata": {},
   "source": [
    "# Transfer-learning tutorial using DenseNet-121 pre-trained model: example on MedNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d343c58-9d11-400f-9e2e-9b0d1e840105",
   "metadata": {},
   "source": [
    "\n",
    "## Goal of this tutoriel\n",
    "\n",
    "This tutorial shows how to do 2d images classification example on MedNIST dataset using pretrained PyTorch model.\n",
    "\n",
    "The goal of this tutorial is to provide an example of transfer learning methods with Fed-BioMed for medical images classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4648375-0340-428a-88cf-97c5a52f5560",
   "metadata": {},
   "source": [
    "### About the model\n",
    "\n",
    "The model used is Densenet-121 model(“Densely Connected Convolutional Networks”) pretrained on ImageNet dataset. The Pytorch pretrained model [Densenet121](https://pytorch.org/vision/main/models/generated/torchvision.models.html). to perform image classification on the MedNIST dataset. \n",
    "The goal of this Densenet121 model is to predict the class of `MedNIST` medical images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463ce8b-8c65-4d51-85ad-47ce8fbc5528",
   "metadata": {},
   "source": [
    "### About MedNIST\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "MedNIST dataset is downloaded from the resources provided by the project [MONAI](https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz)\n",
    "\n",
    "The dataset MedNIST has 58954 images of size (3, 64, 64) distributed into 6 classes (10000 images per class except for BreastMRI class which has 8954 images). Classes are AbdomenCT, BreastMRI, CXR, ChestCT, Hand, HeadCT. It has the structure:\n",
    "\n",
    "└── MedNIST/\n",
    "\n",
    "    ├── AbdomenCT/\n",
    "\n",
    "    └── BreastMRI/\n",
    "\n",
    "    └── CXR/\n",
    "\n",
    "    └── ChestCT/\n",
    "\n",
    "    └── Hand/\n",
    "\n",
    "    └── HeadCT/   \n",
    "   \n",
    "\n",
    "## Transfer-learning\n",
    "Transfer learning is a machine learning technique where a model trained on one task is repurposed or adapted for a second related task. Transfer learning uses a pre-trained neural network on a large dataset, as [Imagenet](https://www.image-net.org) is used to train DenseNet model to perform classification of a wide diversity of images.\n",
    "\n",
    "The objective is that the knowledge gained from learning one task can be useful for learning another task (as we do here, the knowledge of DenseNet model trained on ImageNet is used to classify medical images in 6 categories). This is particularly beneficial when the amount of labeled data for the target task is limited, as the pre-trained model has already learned useful features and representations from a large dataset.\n",
    "\n",
    "Transfer learning is typically applied in one of two ways:\n",
    "\n",
    "- (I) Feature Extraction: In this approach, the pre-trained model is used as a fixed feature extractor. The earlier layers of the neural network, which capture general features and patterns, are frozen, and only the later layers are replaced or retrained for the new task. \n",
    "\n",
    "- (II) Fine-tuning: In this approach, the pre-trained model is further trained or partially trained on the new task. This allows the model to adapt its learned representations to the specifics of the new task while retaining some of the knowledge gained from the original task.\n",
    "\n",
    "\n",
    "In this example, we load on the node a sampled dataset ( 500 or 1500 images) of MedNIST to illustrate the effectiveness of the transfer-learning. The sampled dataset is made with a random selection of images and return a sampled dataset with balanced classes, to avoid classification's bias.\n",
    "We will test these two approches through two independant TrainingPlan experiments. \n",
    "To illustrate the effectiveness of these two methods, we load 500 images for the first experiment and 1500 images for the second. The more data you have, the more layers's you can unfreeze for a transfer learning task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbf14e-d695-4831-8bdf-0e09f7c2f53e",
   "metadata": {},
   "source": [
    "### 1. Load dataset or sampled dataset\n",
    "- From the root directory of Fed-BioMed, run :  `source ./scripts/fedbiomed_environment node` in order to load the Node environment\n",
    "- If you have already ran Mednist nodes before, clean remaining MedNIST nodes : run `./scripts/fedbiomed_run node delete` or `source ./scripts/fedbiomed_environment clean`\n",
    "- In this new environment, run the script python: `python ./notebooks/transfer-learning/download_sample_of_mednist.py -n <number-of-nodes>`, with `<number-of-nodes>` the number of Nodes you want to create( for more details about this script, please run `notebooks/transfer-learning/download_sample_of_mednist.py --help`)\n",
    "- The script will ask for each Nodes created the number of samples you want for your dataset. Scripts will output configuration files for each of Nodes, with configured database, using the following naming convention: `config_mednist_<i>_sampled.ini` where `<i>` is ranged from 1 to `<number-of-nodes>` entered.  \n",
    "- Finally launch your Nodes (one by terminal) by running: `./scripts/fedbiomed_run node config  start config_mednist_<i>_sampled.ini start`, where `<i>` corresponds to the number of Node created.  Wait until you get Starting task manager.\n",
    "\n",
    "For example, if one wants to create 2 nodes, (`<i>` is equal to 2), one has to run : `python ./notebooks/transfer-learning/download_sample_of_mednist.py -n 2`. One will then launch in seperated terminal `./scripts/fedbiomed_run node config config_mednist_1_sampled.ini start` and `./scripts/fedbiomed_run node config config_mednist_2_sampled.ini start`. Script will ask how many sample should contain the dataset (enter 500 and then 1000).\n",
    "\n",
    "\n",
    "\n",
    "### 2. Launch the researcher \n",
    "- From the root directory of Fed-BioMed, run : `./scripts/fedbiomed_run researcher start`\n",
    "- It opens the Jupyter notebook.\n",
    "\n",
    "To make sure that MedNIST dataset is loaded in the node we can send a request to the network to list the available dataset in the node. The list command should output an entry for mednist data.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf52151-a981-4189-8be4-ea5ca03fd120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:12,729 fedbiomed INFO - Starting researcher service..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:12,747 fedbiomed INFO - Waiting 3s for nodes to connect..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:13,358 fedbiomed DEBUG - Node: config_mednist_2_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:13,360 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,760 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,762 fedbiomed DEBUG - Node: config_mednist_2_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'config_mednist_2_sampled': [{'name': 'MedNIST_2_sampled',\n",
       "   'data_type': 'mednist',\n",
       "   'tags': ['#MEDNIST', '#dataset'],\n",
       "   'description': 'MedNIST dataset for transfer learning',\n",
       "   'shape': [1000, 3, 64, 64],\n",
       "   'dataset_id': 'dataset_6f770f6b-3f0e-4aac-8cc9-60f43880dff5',\n",
       "   'dataset_parameters': None}],\n",
       " 'config_mednist_1_sampled': [{'name': 'MedNIST_1_sampled',\n",
       "   'data_type': 'mednist',\n",
       "   'tags': ['#MEDNIST', '#dataset'],\n",
       "   'description': 'MedNIST dataset for transfer learning',\n",
       "   'shape': [500, 3, 64, 64],\n",
       "   'dataset_id': 'dataset_a6a459ef-91b9-45d0-8ba9-6ce940554dc8',\n",
       "   'dataset_parameters': None}]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req  = Requests()\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20148877-d424-4793-9d8b-693d2e47ba44",
   "metadata": {},
   "source": [
    "## Import of librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae87e6a-94ac-4ecf-9586-8f9a353fb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "\n",
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a775bd-4d9e-4f59-9c18-4257ff8ea314",
   "metadata": {},
   "source": [
    "## Run an expriment for image's classification using Transfer-learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567f368-0dc6-4eaa-95a6-1f7a6e78c6e7",
   "metadata": {},
   "source": [
    "### I- Adapt the last layer to your classification's goal\n",
    "Here we use the DenseNet model that allows classification through 10000 samples. \n",
    "We could adapt this classification's task to the MedNIST dataset by replacing the last layer with our classifier. \n",
    "The `model.classifier` layer of the `DenseNet-121` model classifies images through 6 classes, in the Training Plan, by adapting the num_classes value (can be done in through `model_args` argument). \n",
    "\n",
    "### Data augmentation\n",
    "You could perform data augmentation through the preprocess part if you need. Here I show random flip, rotation and crops. \n",
    "You could do the preprocessing of images by doing only transforms.resize, transforms.to_tensor and transforms.normalize, as mentionned in the code below (commented lines). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f5b80",
   "metadata": {},
   "source": [
    "### I -1. Define Training plan experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43761a76-1efc-46cc-80b6-161b3c99731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainingPlan1(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "       \n",
    "        # Load the pre-trained DenseNet model, you have two ways to import your model\n",
    "        \n",
    "        model = models.densenet121()\n",
    "        \n",
    "        \n",
    "        # Remove the classification layer of DenseNet\n",
    "        for param in model.features[:-1].parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # add the classifier \n",
    "        num_classes = model_args['num_classes'] \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier= nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "      \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\",\n",
    "            \"from torchvision.models import densenet121\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    \n",
    "    # training data\n",
    "    \n",
    "    def training_data(self):\n",
    "        \n",
    "\n",
    "        # Transform images and  do data augmentation \n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomVerticalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(30),\n",
    "                #transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7051fed",
   "metadata": {},
   "source": [
    "### Downloading the pretrained model's weights \n",
    "Here I download and save the model's weights through Torch.hub using the command below in a file 'pretrained_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4035e2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ybouilla/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet121')\n",
    "torch.save(model.state_dict(), 'pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a011a997-5fc6-4d01-af73-54c6017da976",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-3}, \n",
    "    'epochs': 2, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'num_classes': 6 # adapt this number to the number of classes in your dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f594a9-8d00-464b-80f1-ff42dac59b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,921 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,922 fedbiomed DEBUG - Node: config_mednist_2_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,923 fedbiomed INFO - Node selected for training -> config_mednist_2_sampled"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,923 fedbiomed INFO - Node selected for training -> config_mednist_1_sampled"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,924 fedbiomed DEBUG - Model file has been saved: /home/ybouilla/Documents/github/fedbiomed/var/experiments/Experiment_0003/model_db321276-8e3c-44d0-a3e8-ead1348765dd.py"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,998 fedbiomed DEBUG - using native torch optimizer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,999 fedbiomed INFO - Removing tensorboard logs from previous experiment"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:15,999 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,000 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,000 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags =  ['#MEDNIST', '#dataset']\n",
    "\n",
    "rounds = 2 # adjsut the number of rounds \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan1,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "# testing section \n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1) \n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12fd54",
   "metadata": {},
   "source": [
    "### I - 2. Define the dataset for your experiment \n",
    "\n",
    "I propose to run this first experiment with only one Node (ie with  MedNIST_sampled_1 dataset, a sub-sampled dataset of 500 MedNIST images), because this first method is a transfer learning without training.\n",
    "\n",
    "Here I show how to select one dataset among the connected datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9688fe37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,004 fedbiomed DEBUG - Experimentation nodes filter changed, you may need to update `training_data`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,005 fedbiomed DEBUG - Experimentation tags changed, you may need to update `training_data`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,005 fedbiomed DEBUG - Training data changed, you may need to update `node_selection_strategy`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,005 fedbiomed DEBUG - Training data changed, you may need to update `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,006 fedbiomed DEBUG - Training data changed, you may need to update `aggregator`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config_mednist_1_sampled': {'name': 'MedNIST_1_sampled', 'data_type': 'mednist', 'tags': ['#MEDNIST', '#dataset'], 'description': 'MedNIST dataset for transfer learning', 'shape': [500, 3, 64, 64], 'dataset_id': 'dataset_a6a459ef-91b9-45d0-8ba9-6ce940554dc8', 'dtypes': [], 'dataset_parameters': None}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exp.set_nodes(['config_mednist_1_sampled'])\n",
    "exp.set_tags(['#MEDNIST', '#dataset'])\n",
    "td = exp.training_data().data()\n",
    "td.pop('config_mednist_2_sampled')\n",
    "exp.set_training_data(td)\n",
    "\n",
    "print(exp.training_data().data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "385d211a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,043 fedbiomed WARNING - 'TorchModel.set_weights' received inputs that did not cover alltrainable model parameters; missing weights: {'classifier.0.weight', 'classifier.3.weight', 'classifier.3.bias', 'classifier.0.bias'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:43:16,044 fedbiomed WARNING - 'TorchModel.set_weights' received inputs with unexpected names: ['classifier.weight', 'classifier.bias']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing the downloaded model\n",
    "\n",
    "exp.training_plan().import_model('pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eee3f6",
   "metadata": {},
   "source": [
    "### I - 3. Run your experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4087e8b5-cad2-4436-9d85-6686717ba8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:44:56,527 fedbiomed INFO - Sampled nodes in round 0 ['config_mednist_1_sampled']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:44:56,536 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
       "\t\t\t\t\t\u001b[1m To\u001b[0m: config_mednist_1_sampled \n",
       "\t\t\t\t\t\u001b[1m Request: \u001b[0m: TRAIN\n",
       " -----------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:44:56,682 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:44:57,942 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 1/15 (7%) | Samples: 32/480\n",
       " \t\t\t\t\t Loss: \u001b[1m1.828450\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:08,504 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 10/15 (67%) | Samples: 320/480\n",
       " \t\t\t\t\t Loss: \u001b[1m0.970067\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:13,254 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 15/15 (100%) | Samples: 450/450\n",
       " \t\t\t\t\t Loss: \u001b[1m1.039150\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:14,288 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 2 | Iteration: 1/15 (7%) | Samples: 32/480\n",
       " \t\t\t\t\t Loss: \u001b[1m0.870862\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:18,423 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 2 | Iteration: 5/15 (33%) | Samples: 160/480\n",
       " \t\t\t\t\t Loss: \u001b[1m0.558594\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:27,766 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 2 | Iteration: 15/15 (100%) | Samples: 450/450\n",
       " \t\t\t\t\t Loss: \u001b[1m1.057021\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:29,390 fedbiomed INFO - \u001b[1mVALIDATION ON LOCAL UPDATES\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 50/50\n",
       " \t\t\t\t\t ACCURACY: \u001b[1m0.680000\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:29,554 fedbiomed INFO - Nodes that successfully reply in round 0 ['config_mednist_1_sampled']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:29,626 fedbiomed INFO - Saved aggregated params for round 0 in /home/ybouilla/Documents/github/fedbiomed/var/experiments/Experiment_0003/aggregated_params_50fb2c99-6db5-4f25-a945-a5ab12cd98e7.mpk"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:29,627 fedbiomed INFO - Sampled nodes in round 1 ['config_mednist_1_sampled']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:29,634 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
       "\t\t\t\t\t\u001b[1m To\u001b[0m: config_mednist_1_sampled \n",
       "\t\t\t\t\t\u001b[1m Request: \u001b[0m: TRAIN\n",
       " -----------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:29,758 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:31,105 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 1/15 (7%) | Samples: 32/480\n",
       " \t\t\t\t\t Loss: \u001b[1m0.531151\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:41,242 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 10/15 (67%) | Samples: 320/480\n",
       " \t\t\t\t\t Loss: \u001b[1m0.264961\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:45,338 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 2 Epoch: 1 | Iteration: 15/15 (100%) | Samples: 450/450\n",
       " \t\t\t\t\t Loss: \u001b[1m0.528422\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:46,345 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 2 Epoch: 2 | Iteration: 1/15 (7%) | Samples: 32/480\n",
       " \t\t\t\t\t Loss: \u001b[1m0.576321\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:45:50,381 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 2 Epoch: 2 | Iteration: 5/15 (33%) | Samples: 160/480\n",
       " \t\t\t\t\t Loss: \u001b[1m0.608623\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:46:00,587 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 2 Epoch: 2 | Iteration: 15/15 (100%) | Samples: 450/450\n",
       " \t\t\t\t\t Loss: \u001b[1m1.102158\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:46:02,344 fedbiomed INFO - \u001b[1mVALIDATION ON LOCAL UPDATES\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 50/50\n",
       " \t\t\t\t\t ACCURACY: \u001b[1m0.880000\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:46:02,478 fedbiomed INFO - Nodes that successfully reply in round 1 ['config_mednist_1_sampled']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:46:02,543 fedbiomed INFO - Saved aggregated params for round 1 in /home/ybouilla/Documents/github/fedbiomed/var/experiments/Experiment_0003/aggregated_params_b29b2723-7a22-4098-a9a9-f51decb887fd.mpk"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 12:37:43,481 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 12:42:49,764 fedbiomed DEBUG - Node: config_mednist_2_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecf6a7-eb26-4b9c-bc24-492c8cb030b8",
   "metadata": {},
   "source": [
    "###### For example,  At the end of training experiment, I obtained\n",
    "\n",
    "                      INFO - VALIDATION ON LOCAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: NODE_41cd99c8-3571-4ab3-958e-6357ce31e91b \n",
    "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 0.980000\n",
    "\t\t\t\t\t -\n",
    "\n",
    "As you can see, Accuracy has been increased in comparison to the first `Expermient`   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600b2ce",
   "metadata": {},
   "source": [
    "### I - 4. Save your model \n",
    "You could save your model to later use it in a new TrainingPlan \n",
    "This save allows to import the model including your layers's modification and weights values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "244b54a8-43a0-4009-8e3e-07e62fec2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "exp.training_plan().export_model('./training_plan1_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5263f76b",
   "metadata": {},
   "source": [
    "### I - 5. Results in tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326ace09-7f4d-40fd-8646-c3f4cb67042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "tensorboard_dir = environ['TENSORBOARD_RESULTS_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31041e7e-728d-4b18-a5d7-58f405bd1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c8bdb39-287e-4cc4-973d-1dfb30838aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b186463198a5f1a4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b186463198a5f1a4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07027428-86f9-4f0f-87da-b8b97da6838e",
   "metadata": {},
   "source": [
    "## II - Partial fine-tuning: Use pretrained DenseNet and train specific layers with your data\n",
    "You can set the second dataset with more images to run the second experiment that uses training steps. \n",
    "\n",
    "In this example, I run a second experiment with 1500 images (from both nodes).\n",
    "The dataset is defined below, after TrainingPlan as previously shown.\n",
    "\n",
    "You could also import the model you saved to perform your second TrainingPlan experiment (let's see below)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c1a2f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:03:58,042 fedbiomed DEBUG - Node: config_mednist_2_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:03:58,044 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'config_mednist_1_sampled': [{'name': 'MedNIST_1_sampled',\n",
       "   'data_type': 'mednist',\n",
       "   'tags': ['#MEDNIST', '#dataset'],\n",
       "   'description': 'MedNIST dataset for transfer learning',\n",
       "   'shape': [500, 3, 64, 64],\n",
       "   'dataset_id': 'dataset_a6a459ef-91b9-45d0-8ba9-6ce940554dc8',\n",
       "   'dataset_parameters': None}],\n",
       " 'config_mednist_2_sampled': [{'name': 'MedNIST_2_sampled',\n",
       "   'data_type': 'mednist',\n",
       "   'tags': ['#MEDNIST', '#dataset'],\n",
       "   'description': 'MedNIST dataset for transfer learning',\n",
       "   'shape': [1000, 3, 64, 64],\n",
       "   'dataset_id': 'dataset_6f770f6b-3f0e-4aac-8cc9-60f43880dff5',\n",
       "   'dataset_parameters': None}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req  = Requests()\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33207b0-6d38-4cb6-a1ed-7ea18e55b1ea",
   "metadata": {},
   "source": [
    "Here I freeze 3 layers since we have a bigger dataset than in the first part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a62ced6-f7e6-406f-8dfe-77e620aa3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "class MyTrainingPlan2(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "\n",
    "        # Load the pre-trained DenseNet model\n",
    "        model = models.densenet121(pretrained=True)\n",
    "       \n",
    "        # For example, let's freeze layers of the last dense block\n",
    "        for param in model.features[:-3].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # add the classifier \n",
    "        num_ftrs = model.classifier.in_features\n",
    "        num_classes = model_args['num_classes'] \n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes)       \n",
    "            )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    def training_data(self):\n",
    "        \n",
    "        # Custom torch Dataloader for MedNIST data and transform images and perform data augmentation \n",
    "       \n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomVerticalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(30),\n",
    "                #transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "620f3099-b6e6-4395-b9ea-ad2b728d0370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,306 fedbiomed DEBUG - Node: config_mednist_2_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,308 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,310 fedbiomed INFO - Node selected for training -> config_mednist_1_sampled"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,310 fedbiomed INFO - Node selected for training -> config_mednist_2_sampled"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,312 fedbiomed DEBUG - Model file has been saved: /home/ybouilla/Documents/github/fedbiomed/var/experiments/Experiment_0001/model_75ee9d4f-9e1d-4232-91ae-4fdc7cfb4548.py"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,406 fedbiomed DEBUG - using native torch optimizer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,407 fedbiomed INFO - Removing tensorboard logs from previous experiment"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,410 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,411 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:01,412 fedbiomed DEBUG - Experimentation training_args updated for `job`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n",
    "\n",
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-4}, # You could decrease the learning rate\n",
    "    'epochs': 1, # you can increase the epoch's number =10\n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "model_args={\n",
    "    'num_classes': 6\n",
    "}\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "rounds = 1  # you can increase the rounds's number \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan2,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1)\n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb58d926",
   "metadata": {},
   "source": [
    "### II - 1. (Optional) Import a \"custom model\" or continue with the original DenseNet model of the TrainingPlan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25160054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:03,825 fedbiomed WARNING - 'TorchModel.set_weights' received inputs that did not cover alltrainable model parameters; missing weights: {'classifier.2.bias', 'classifier.2.weight'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:03,826 fedbiomed WARNING - 'TorchModel.set_weights' received inputs with unexpected names: ['classifier.3.weight', 'classifier.3.bias']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.training_plan().import_model('./training_plan1_densenet_MedNIST') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829e80f",
   "metadata": {},
   "source": [
    "### II - 2. Run your experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35d3e1a9-b0c8-4bbc-b397-0d0b6b14ab55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:04,132 fedbiomed INFO - Sampled nodes in round 0 ['config_mednist_1_sampled', 'config_mednist_2_sampled']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:04,141 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
       "\t\t\t\t\t\u001b[1m To\u001b[0m: config_mednist_1_sampled \n",
       "\t\t\t\t\t\u001b[1m Request: \u001b[0m: TRAIN\n",
       " -----------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:04,142 fedbiomed INFO - \u001b[1mSending request\u001b[0m \n",
       "\t\t\t\t\t\u001b[1m To\u001b[0m: config_mednist_2_sampled \n",
       "\t\t\t\t\t\u001b[1m Request: \u001b[0m: TRAIN\n",
       " -----------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:04,294 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:04,318 fedbiomed DEBUG - Node: config_mednist_2_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:44,266 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 1/15 (7%) | Samples: 32/480\n",
       " \t\t\t\t\t Loss: \u001b[1m2.186399\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:04:46,610 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_2_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 1/29 (3%) | Samples: 32/928\n",
       " \t\t\t\t\t Loss: \u001b[1m2.166163\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:10:33,504 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 10/15 (67%) | Samples: 320/480\n",
       " \t\t\t\t\t Loss: \u001b[1m0.997464\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:10:34,818 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_2_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 10/29 (34%) | Samples: 320/928\n",
       " \t\t\t\t\t Loss: \u001b[1m1.067292\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:12:58,339 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 15/15 (100%) | Samples: 450/450\n",
       " \t\t\t\t\t Loss: \u001b[1m0.917216\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:13:28,106 fedbiomed INFO - \u001b[1mVALIDATION ON LOCAL UPDATES\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_1_sampled \n",
       "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 50/50\n",
       " \t\t\t\t\t ACCURACY: \u001b[1m0.980000\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:13:34,519 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_2_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 20/29 (69%) | Samples: 640/928\n",
       " \t\t\t\t\t Loss: \u001b[1m0.497512\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:13:45,106 fedbiomed INFO - \u001b[1mTRAINING\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_2_sampled \n",
       "\t\t\t\t\t Round 1 Epoch: 1 | Iteration: 29/29 (100%) | Samples: 900/900\n",
       " \t\t\t\t\t Loss: \u001b[1m0.312345\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:13:48,719 fedbiomed INFO - \u001b[1mVALIDATION ON LOCAL UPDATES\u001b[0m \n",
       "\t\t\t\t\t NODE_ID: config_mednist_2_sampled \n",
       "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 100/100\n",
       " \t\t\t\t\t ACCURACY: \u001b[1m1.000000\u001b[0m \n",
       "\t\t\t\t\t ---------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:13:48,885 fedbiomed INFO - Nodes that successfully reply in round 0 ['config_mednist_1_sampled', 'config_mednist_2_sampled']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:13:48,959 fedbiomed INFO - Saved aggregated params for round 0 in /home/ybouilla/Documents/github/fedbiomed/var/experiments/Experiment_0001/aggregated_params_698dd230-5aca-4c76-8003-7b8ededf7317.mpk"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 10:53:12,727 fedbiomed DEBUG - Node: config_mednist_1_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2024-02-23 11:02:49,072 fedbiomed DEBUG - Node: config_mednist_2_sampled polling for the tasks"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaec824-4a01-4c29-b9d9-f4543c8d56ff",
   "metadata": {},
   "source": [
    "For example,  At the end of training experiment, I obtained\n",
    "\n",
    "                    fedbiomed INFO - VALIDATION ON LOCAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: NODE_7842724a-cafa-49cc-862d-149288bbbb22 \n",
    "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 1.00000\n",
    "\t\t\t\t\t ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394f0b1-5795-479e-a544-dc07913ac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1]\n",
    "for r in round_data.values():\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = r['node_id'],\n",
    "        rtraining = r['timing']['rtime_training'],\n",
    "        ptraining = r['timing']['ptime_training'],\n",
    "        rtotal = r['timing']['rtime_total']))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f51d1b-960f-4b4b-b301-7c7ea7c68c9a",
   "metadata": {},
   "source": [
    "### II -  3. Export your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "exp.training_plan().export_model('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2acea",
   "metadata": {},
   "source": [
    "### II - 4. Display losses on Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d301fa3-50e7-4aee-96d6-b85bed457fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b73071-f09b-4a87-a0a6-d525ce39c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4668ca",
   "metadata": {},
   "source": [
    "### II - 5. Save and Import your model and parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39efaf44",
   "metadata": {},
   "source": [
    "You could import your first model from TrainingPlan1 instead of loading the original DenseNet.\n",
    "You could also retrieve the model's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model ( all layers model of te training experiment)\n",
    "remote_model = exp.training_plan().model()  \n",
    "torch.save(remote_model, './training_plan2_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e906de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your model \n",
    "model= torch.load('./training_plan2_model')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b05c4",
   "metadata": {},
   "source": [
    "### II - 6. Save model's features, parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = exp.training_plan().export_model('./training_plan2_model')\n",
    "model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c18ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your model's layers features\n",
    "model_features_= torch.load('./training_plan2_model')\n",
    "model_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6510f7d-d612-476a-98aa-5aef2651f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent commands \n",
    "remote_model = exp.training_plan().model()\n",
    "remote_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
