{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73501475-4e1f-454c-bc16-0320ecd51d57",
   "metadata": {},
   "source": [
    "# MedNIST dataset using DenseNet Transfer Learning¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463ce8b-8c65-4d51-85ad-47ce8fbc5528",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial shows how to do 2d image classification example on MedNIST dataset using pretrained PyTorch model Densnet121 https://pytorch.org/vision/main/generated/torchvision.models.densenet121.html.\n",
    "\n",
    "About MedNIST\n",
    "\n",
    "MedNIST provides an artificial 2d classification dataset created by gathering different medical imaging datasets from TCIA, the RSNA Bone Age Challenge, and the NIH Chest X-ray dataset. The dataset is kindly made available by Dr. Bradley J. Erickson M.D., Ph.D. (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license.\n",
    "\n",
    "MedNIST dataset is downloaded from the resources provided by the project MONAI: https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\n",
    "\n",
    "The dataset MedNIST has 58954 images of size (3, 64, 64) distributed into 6 classes (10000 images per class except for BreastMRI class which has 8954 images). Classes are AbdomenCT, BreastMRI, CXR, ChestCT, Hand, HeadCT. It has the structure:\n",
    "\n",
    "└── MedNIST/\n",
    "\n",
    "├── AbdomenCT/\n",
    "\n",
    "└── BreastMRI/\n",
    "\n",
    "└── CXR/\n",
    "\n",
    "└── ChestCT/\n",
    "\n",
    "└── Hand/\n",
    "\n",
    "└── HeadCT/   \n",
    "\n",
    "\n",
    "In this example, we load on the node a sampled dataset ( 500 or 1000 images) of MedNIST to illustrate the effectiveness of the transfer learning. The sampled dataset is made with a random selection of images and return a sampled datset with balanced classes, to avoid classification's bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4648375-0340-428a-88cf-97c5a52f5560",
   "metadata": {},
   "source": [
    "## About the model\n",
    "\n",
    "The model used is Densenet-121 model(“Densely Connected Convolutional Networks”) pretrained on ImageNet dataset. The Pytorch pretrained Densenet121 is used https://pytorch.org/vision/main/generated/torchvision.models.densenet121.html to perform image classification on the MedNIST dataset. \n",
    "The goal of this Densenet121 model is to predict the class of the image modality given the medical image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef72375-5f3e-4e29-b619-e172055a01b5",
   "metadata": {},
   "source": [
    "## Setup the node\n",
    "\n",
    "- From the folder fedbiomed, execute the command ./scripts/fedbiomed_run node add\n",
    "\n",
    "- Select option 3 (mednist) to add MedNIST to the node\n",
    "- Confirm mednist tags ['#MEDNIST', '#dataset'] by hitting \"y\" and ENTER\n",
    "- Select the folder where MedNIST is downloaded (It will be downloaded if it is not found in the selected path)\n",
    "Data must have been added (if you get a warning saying that data must be unique is because it's been already added)\n",
    "- Enter the amount's sample you want to run in your experiment.\n",
    "\n",
    "- Check that your data has been added by executing ./scripts/fedbiomed_run node list\n",
    "- Start the node using ./scripts/fedbiomed_run node start. Wait until you get Starting task manager.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9e20f-6b16-4150-a3a4-1f4a2c468aa5",
   "metadata": {},
   "source": [
    "## Start Fed-BioMed Researcher\n",
    "\n",
    "We are now ready to start the researcher environment with the command source ./scripts/fedbiomed_run researcher start\n",
    ", and open the Jupyter notebook.\n",
    "\n",
    "To make sure that MedNIST dataset is loaded in the node we can send a request to the network to list the available dataset in the node. The list command should output an entry for mednist data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf52151-a981-4189-8be4-ea5ca03fd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req  = Requests()\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20148877-d424-4793-9d8b-693d2e47ba44",
   "metadata": {},
   "source": [
    "## Import of librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae87e6a-94ac-4ecf-9586-8f9a353fb109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fedbiomed.common.training_plans import TorchTrainingPlan\n",
    "from fedbiomed.common.data import DataManager\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import densenet121\n",
    "from torchvision import datasets, transforms, models\n",
    "from fedbiomed.researcher.experiment import Experiment\n",
    "from fedbiomed.researcher.aggregators.fedavg import FedAverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b66b5-af52-45e4-944b-572fb12504dc",
   "metadata": {},
   "source": [
    "## Classification using Transfer-learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a43f9-061b-49a8-a66f-30f9077c773b",
   "metadata": {},
   "source": [
    "### Declare and run the experiment\n",
    "\n",
    "- search nodes serving data for these `tags`, optionally filter on a list of node ID with `nodes`\n",
    "- run a round of local training on nodes with model defined in `model_path` + federation with `aggregator`\n",
    "- run for `round_limit` rounds, applying the `node_selection_strategy` between the rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43761a76-1efc-46cc-80b6-161b3c99731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainingPlan1(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "       \n",
    "        # Load the pre-trained DenseNet model\n",
    "        model = models.densenet121(pretrained=False)\n",
    "        \n",
    "        # remove the classification layer \n",
    "        for param in model.features[:-1].parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        num_classes = model_args['num_classes'] # Change this to the number of classes in your dataset model_args section below\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier= nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "      \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\",\n",
    "            \"from torchvision.models import densenet121\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    # training data\n",
    "    \n",
    "\n",
    "    def training_data(self):\n",
    "        \n",
    "        # Custom torch Dataloader for MedNIST data\n",
    "        print(\"dataset path\",self.dataset_path)\n",
    "\n",
    "        # Transform images and  do data augmentation \n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(30),\n",
    "                transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "    \n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011a997-5fc6-4d01-af73-54c6017da976",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-4}, \n",
    "    'epochs': 2, \n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "\n",
    "model_args = {\n",
    "    'num_classes': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f594a9-8d00-464b-80f1-ff42dac59b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "\n",
    "rounds = 2 # adjsut the number of rounds \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan1,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "# testing section \n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1) \n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0d36e-cbd8-4d69-836c-20d83d13d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.training_plan().import_model('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4087e8b5-cad2-4436-9d85-6686717ba8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ecf6a7-eb26-4b9c-bc24-492c8cb030b8",
   "metadata": {},
   "source": [
    " \n",
    "For example,  At the end of training experiment, I obtained\n",
    "\n",
    "                      INFO - VALIDATION ON LOCAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: NODE_41cd99c8-3571-4ab3-958e-6357ce31e91b \n",
    "\t\t\t\t\t Round 2 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 0.700000 \n",
    "\t\t\t\t\t -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b54a8-43a0-4009-8e3e-07e62fec2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and  weights. You have the choice to import the model for other experiment \n",
    "exp.training_plan().export_model('./training_plan1_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ace09-7f4d-40fd-8646-c3f4cb67042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.environ import environ\n",
    "tensorboard_dir = environ['TENSORBOARD_RESULTS_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31041e7e-728d-4b18-a5d7-58f405bd1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8bdb39-287e-4cc4-973d-1dfb30838aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072c19d-f932-4926-8290-349601908054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6699bc5e-c3a0-46ca-8162-9a52a8c2d020",
   "metadata": {},
   "source": [
    "## Upload more data and train the top layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71095e37-bcc7-44f0-b049-15401e25d1e5",
   "metadata": {},
   "source": [
    "You can load more data on a new node for the second experiment and train top layers of the denseNet model.\n",
    "To cange the amount of data, you have to stop the previous node in the console by tapping CTL+C.\n",
    "\n",
    "In this example, I run a second experiment with 1000 images.\n",
    "Run an other node with 1000 images (as previously described above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59fb9cb-0ff6-4d5b-935f-a6f7d5eae3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedbiomed.researcher.requests import Requests\n",
    "req  = Requests()\n",
    "req.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07027428-86f9-4f0f-87da-b8b97da6838e",
   "metadata": {},
   "source": [
    "## Partial fine-tuning: Use pretrained DenseNet and train Top layers with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62ced6-f7e6-406f-8dfe-77e620aa3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainingPlan2(TorchTrainingPlan):\n",
    "\n",
    "    def init_model(self, model_args):\n",
    "\n",
    "        # Load the pre-trained DenseNet model\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # For example, let's freeze layers of the last dense block\n",
    "        for param in model.features[:-3].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Modify the classifier to match the number of classes in your dataset\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        num_classes = model_args['num_classes'] \n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, num_classes)\n",
    "           \n",
    "            )\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def init_dependencies(self):\n",
    "        return [\n",
    "            \"from torchvision import datasets, transforms, models\",\n",
    "            \"import torch.optim as optim\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def init_optimizer(self, optimizer_args):        \n",
    "        return optim.Adam(self.model().parameters(), lr=optimizer_args[\"lr\"])\n",
    "\n",
    "    def training_data(self):\n",
    "        \n",
    "        # Custom torch Dataloader for MedNIST data\n",
    "        print(\"dataset path\",self.dataset_path)\n",
    "        preprocess = transforms.Compose([\n",
    "                transforms.Resize((224,224)),  \n",
    "                #transforms.RandomHorizontalFlip(p=0.5),\n",
    "                #transforms.RandomVerticalFlip(p=0.5),\n",
    "                #transforms.RandomRotation(30),\n",
    "                #transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "           ])\n",
    "        train_data = datasets.ImageFolder(self.dataset_path,transform = preprocess)\n",
    "        train_kwargs = { 'shuffle': True}\n",
    "        return DataManager(dataset=train_data, **train_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    def training_step(self, data, target):\n",
    "        output = self.model().forward(data)\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss   = loss_func(output, target)\n",
    "        return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f3099-b6e6-4395-b9ea-ad2b728d0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    'loader_args': { 'batch_size': 32, }, \n",
    "    'optimizer_args': {'lr': 1e-4}, \n",
    "    'epochs': 1, # you can increase the epoch's number =10\n",
    "    'dry_run': False,  \n",
    "    'batch_maxnum': 100 # Fast pass for development : only use ( batch_maxnum * batch_size ) samples\n",
    "}\n",
    "model_args={\n",
    "    'num_classes': 6\n",
    "}\n",
    "tags =  ['#MEDNIST', '#dataset']\n",
    "rounds = 1  # you can increase the rounds's number \n",
    "\n",
    "exp = Experiment(tags=tags,\n",
    "                 training_plan_class=MyTrainingPlan2,\n",
    "                 model_args=model_args,\n",
    "                 training_args=training_args,\n",
    "                 round_limit=rounds,\n",
    "                 aggregator=FedAverage())\n",
    "\n",
    "from fedbiomed.common.metrics import MetricTypes\n",
    "exp.set_test_ratio(.1)\n",
    "exp.set_test_on_local_updates(True)\n",
    "exp.set_test_metric(MetricTypes.ACCURACY)\n",
    "\n",
    "exp.set_tensorboard(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3e1a9-b0c8-4bbc-b397-0d0b6b14ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ba782-cc22-41b8-96ec-f975f1e493ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "For example,  At the end of training experiment, I obtained\n",
    "\n",
    "                    fedbiomed INFO - VALIDATION ON LOCAL UPDATES \n",
    "\t\t\t\t\t NODE_ID: NODE_7842724a-cafa-49cc-862d-149288bbbb22 \n",
    "\t\t\t\t\t Round 1 | Iteration: 1/1 (100%) | Samples: 100/100\n",
    " \t\t\t\t\t ACCURACY: 0.980000 \n",
    "\t\t\t\t\t ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394f0b1-5795-479e-a544-dc07913ac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nList the training rounds : \", exp.training_replies().keys())\n",
    "\n",
    "print(\"\\nList the nodes for the last training round and their timings : \")\n",
    "round_data = exp.training_replies()[rounds - 1]\n",
    "for r in round_data.values():\n",
    "    print(\"\\t- {id} :\\\n",
    "    \\n\\t\\trtime_training={rtraining:.2f} seconds\\\n",
    "    \\n\\t\\tptime_training={ptraining:.2f} seconds\\\n",
    "    \\n\\t\\trtime_total={rtotal:.2f} seconds\".format(id = r['node_id'],\n",
    "        rtraining = r['timing']['rtime_training'],\n",
    "        ptraining = r['timing']['ptime_training'],\n",
    "        rtotal = r['timing']['rtime_total']))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d301fa3-50e7-4aee-96d6-b85bed457fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b73071-f09b-4a87-a0a6-d525ce39c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir \"$tensorboard_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f51d1b-960f-4b4b-b301-7c7ea7c68c9a",
   "metadata": {},
   "source": [
    "## Save and export your model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a311890f-bab1-4970-a501-98f285d70fbd",
   "metadata": {},
   "source": [
    "You can save the TrainingPlan experiment and the fine-tune model by executing the command below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e2eb8-2441-4966-a619-5bf587db2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.training_plan().export_model('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d0692-df7f-490c-a250-39758470349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model ( all layers model of te training experiment)\n",
    "remote_model = exp.training_plan().model()\n",
    "torch.save(remote_model, './training_plan2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdc0bb-be22-46e3-944a-9cdbd8162a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torchvision import models\n",
    "\n",
    "#torch.save(models.densenet121(pretrained=True).state_dict(), './model_training_plan_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428af67-79a8-4cee-8b6b-ad5b010bb411",
   "metadata": {},
   "source": [
    "## Import your model and parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e589df-9589-4a78-9878-790f83e0cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model = torch.load('./training_plan2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1457eeeb-0618-4f0e-adaa-e0ce03ab21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your parameters (tensors's values of your tuned-model)\n",
    "tuned_model= torch.load('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b4373-1716-417a-8b28-fd1dfc76ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new TrainingPlan experiment you could import your tuned-model \n",
    "exp.training_plan().import_model('./training_plan2_densenet_MedNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef8f1a-7b6b-4e3b-8351-a78d97964084",
   "metadata": {},
   "source": [
    "### This part needs confirmation, tests,( and agreements to load parameters ? ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6510f7d-d612-476a-98aa-5aef2651f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remote_model = remote_experiment.training_plan().model()\n",
    "tuned_model.load_state_dict(remote_experiment.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e0cc6-770e-4a34-8037-9eae06bd45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])\n",
    "#tuned_model.load_state_dict(remote_experiment.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7346c-d6fb-45d3-804e-e56b0e9f3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.load_state_dict(exp.aggregated_params()[rounds - 1]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82550831-bf50-480e-a0a9-f16511c48e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
